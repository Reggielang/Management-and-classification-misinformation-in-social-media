{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Use machine learning methods to  make a model for  identify aggressive tweet\n",
    "1.Use OLID's tweet training dataset\n",
    "reference: https://sites.google.com/site/offensevalsharedtask/olid\n",
    "\n",
    "2.the processing of train text data \n",
    "\n",
    "3.the processing of test text data\n",
    "\n",
    "4.Build model\n",
    "\n",
    "5.testing model and optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'D:\\dataset\\clear_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>86426</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>90194</td>\n",
       "      <td>@USER @USER Go home you鈥檙e drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>16820</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>62688</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>43605</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet subtask_a  \\\n",
       "0  86426  @USER She should ask a few native Americans wh...       OFF   \n",
       "1  90194  @USER @USER Go home you鈥檙e drunk!!! @USER #MAG...       OFF   \n",
       "2  16820  Amazon is investigating Chinese employees who ...       NOT   \n",
       "3  62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
       "4  43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
       "\n",
       "  subtask_b subtask_c  \n",
       "0       UNT       NaN  \n",
       "1       TIN       IND  \n",
       "2       NaN       NaN  \n",
       "3       UNT       NaN  \n",
       "4       NaN       NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLID_trainset = pd.read_csv('olid-training-v1.0.csv')\n",
    "OLID_trainset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLID_trainset = OLID_trainset[['tweet','subtask_a']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLID_trainset = OLID_trainset.rename(columns = {'subtask_a':'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@USER @USER Go home you鈥檙e drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet label\n",
       "0  @USER She should ask a few native Americans wh...   OFF\n",
       "1  @USER @USER Go home you鈥檙e drunk!!! @USER #MAG...   OFF\n",
       "2  Amazon is investigating Chinese employees who ...   NOT\n",
       "3  @USER Someone should'veTaken\" this piece of sh...   OFF\n",
       "4  @USER @USER Obama wanted liberals &amp; illega...   NOT"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLID_trainset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getscore(score):\n",
    "    if score == 'OFF':\n",
    "        return 1\n",
    "    elif score == 'NOT':\n",
    "        return 0\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLID_trainset.label = OLID_trainset.label.apply(getscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLID_trainset.dropna(subset=['label'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@USER @USER Go home you鈥檙e drunk!!! @USER #MAG...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0  @USER She should ask a few native Americans wh...    1.0\n",
       "1  @USER @USER Go home you鈥檙e drunk!!! @USER #MAG...    1.0\n",
       "2  Amazon is investigating Chinese employees who ...    0.0\n",
       "3  @USER Someone should'veTaken\" this piece of sh...    1.0\n",
       "4  @USER @USER Obama wanted liberals &amp; illega...    0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLID_trainset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The processing of train text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     she should ask a few native americans what th...\n",
       "1      go home you鈥檙e drunk!!!  maga trump2020 馃憡馃嚭...\n",
       "2    amazon is investigating chinese employees who ...\n",
       "3     someone should'vetaken\" this piece of shit to...\n",
       "4      obama wanted liberals &amp; illegals to move...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out some useless handles\n",
    "import re\n",
    "reg_map = {\n",
    "    re.compile(\"rt [@0-9a-z_]{0,10}:\"),\n",
    "    re.compile(\"[a-zA-z]+://[^\\s]*\"),\n",
    "    re.compile('http|htttps…'),\n",
    "    re.compile('[a-z]*[:.]+\\S+'),\n",
    "    re.compile(\"@[0-9a-z]+\"),\n",
    "    re.compile(\"RT[\\s]+\"),\n",
    "    re.compile(\"#\"),\n",
    "    re.compile('https?:\\/\\/\\S+'),\n",
    "}\n",
    "def lower_and_remove_with_reg(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    for v in reg_map:\n",
    "        text = v.sub(\"\", text)\n",
    "    return text\n",
    "\n",
    "# Filter out some useless handles\n",
    "OLID_trainset['tweet']=OLID_trainset['tweet'].apply(lower_and_remove_with_reg)\n",
    "OLID_trainset['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replaces periods with Spaces\n",
    "OLID_trainset['tweet'] =  OLID_trainset['tweet'].str.replace('[^a-zA-Z]', ' ') \n",
    "\n",
    "#Delete the short term\n",
    "OLID_trainset['tweet'] =  OLID_trainset['tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                native americans take\n",
       "1                                home drunk maga trump\n",
       "2    amazon investigating chinese employees selling...\n",
       "3                   someone vetaken piece shit volcano\n",
       "4           obama wanted liberals illegals move states\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop=stopwords.words('english')\n",
    "OLID_trainset['tweet'] =  OLID_trainset['tweet'].apply(lambda sen:\" \".join(x for x in sen.split() if x not in stop))\n",
    "OLID_trainset['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 native american take\n",
       "1                                home drunk maga trump\n",
       "2    amazon investigating chinese employee selling ...\n",
       "3                   someone vetaken piece shit volcano\n",
       "4             obama wanted liberal illegals move state\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Part of speech reduction\n",
    "from textblob import Word\n",
    "OLID_trainset['tweet'] =  OLID_trainset['tweet'].apply(lambda x:\" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "OLID_trainset['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                             [native, american, take]\n",
       "1                           [home, drunk, maga, trump]\n",
       "2    [amazon, investigating, chinese, employee, sel...\n",
       "3             [someone, vetaken, piece, shit, volcano]\n",
       "4      [obama, wanted, liberal, illegals, move, state]\n",
       "Name: word, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Delete handle\n",
    "#Participle\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import pos_tag\n",
    "tknzr = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "OLID_trainset['word'] =  OLID_trainset['tweet'].apply(tknzr.tokenize)\n",
    "OLID_trainset['word'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part-of-speech tagging\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "def get_pos(text):\n",
    "    token = word_tokenize(text)\n",
    "    word = (pos_tag(token))\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           [(native, JJ), (american, JJ), (take, NN)]\n",
       "1    [(home, NN), (drunk, NN), (maga, NN), (trump, ...\n",
       "2    [(amazon, NN), (investigating, VBG), (chinese,...\n",
       "3    [(someone, NN), (vetaken, VBD), (piece, NN), (...\n",
       "4    [(obama, RB), (wanted, VBD), (liberal, JJ), (i...\n",
       "Name: text_tag, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLID_trainset['text_tag'] =  OLID_trainset['tweet'].apply(get_pos)\n",
    "OLID_trainset['text_tag'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>word</th>\n",
       "      <th>text_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>native american take</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[native, american, take]</td>\n",
       "      <td>[(native, JJ), (american, JJ), (take, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>home drunk maga trump</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[home, drunk, maga, trump]</td>\n",
       "      <td>[(home, NN), (drunk, NN), (maga, NN), (trump, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>amazon investigating chinese employee selling ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[amazon, investigating, chinese, employee, sel...</td>\n",
       "      <td>[(amazon, NN), (investigating, VBG), (chinese,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>someone vetaken piece shit volcano</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[someone, vetaken, piece, shit, volcano]</td>\n",
       "      <td>[(someone, NN), (vetaken, VBD), (piece, NN), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>obama wanted liberal illegals move state</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[obama, wanted, liberal, illegals, move, state]</td>\n",
       "      <td>[(obama, RB), (wanted, VBD), (liberal, JJ), (i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label  \\\n",
       "0                               native american take    1.0   \n",
       "1                              home drunk maga trump    1.0   \n",
       "2  amazon investigating chinese employee selling ...    0.0   \n",
       "3                 someone vetaken piece shit volcano    1.0   \n",
       "4           obama wanted liberal illegals move state    0.0   \n",
       "\n",
       "                                                word  \\\n",
       "0                           [native, american, take]   \n",
       "1                         [home, drunk, maga, trump]   \n",
       "2  [amazon, investigating, chinese, employee, sel...   \n",
       "3           [someone, vetaken, piece, shit, volcano]   \n",
       "4    [obama, wanted, liberal, illegals, move, state]   \n",
       "\n",
       "                                            text_tag  \n",
       "0         [(native, JJ), (american, JJ), (take, NN)]  \n",
       "1  [(home, NN), (drunk, NN), (maga, NN), (trump, ...  \n",
       "2  [(amazon, NN), (investigating, VBG), (chinese,...  \n",
       "3  [(someone, NN), (vetaken, VBD), (piece, NN), (...  \n",
       "4  [(obama, RB), (wanted, VBD), (liberal, JJ), (i...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLID_trainset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]                                                                                                                           335\n",
       "[fuck]                                                                                                                        23\n",
       "[liberal]                                                                                                                     15\n",
       "[good]                                                                                                                        14\n",
       "[beautiful]                                                                                                                   13\n",
       "                                                                                                                            ... \n",
       "[trump, fucking, asshole, think, otherwise, idiot, friend, hurt, need, educated, educate, everyday, talk, everyday, stfu]      1\n",
       "[photoshopped]                                                                                                                 1\n",
       "[believe, feinstein, upstanding, would, never, china, employee, year, need, resign, trader]                                    1\n",
       "[basically, another, dead]                                                                                                     1\n",
       "[look, antifa, written]                                                                                                        1\n",
       "Name: word, Length: 12324, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLID_trainset.word.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12789 entries, 0 to 13239\n",
      "Data columns (total 4 columns):\n",
      "tweet       12789 non-null object\n",
      "label       12789 non-null float64\n",
      "word        12789 non-null object\n",
      "text_tag    12789 non-null object\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 499.6+ KB\n"
     ]
    }
   ],
   "source": [
    "OLID_trainset = OLID_trainset[OLID_trainset.word.str.len() != 0] \n",
    "OLID_trainset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLID_trainset = OLID_trainset[['tweet','word','text_tag','label']]\n",
    "OLID_trainset.to_csv('OLID_trainset.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The processing of test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>15923</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>27014</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>30530</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13876</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>60133</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id label\n",
       "0  15923   OFF\n",
       "1  27014   NOT\n",
       "2  30530   NOT\n",
       "3  13876   NOT\n",
       "4  60133   OFF"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(r'D:\\dataset\\clear_data')\n",
    "OLID_testset = pd.read_csv(r'labels-testset.csv')\n",
    "OLID_testset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getscore(score):\n",
    "    if score == 'OFF':\n",
    "        return 1\n",
    "    elif score == 'NOT':\n",
    "        return 0\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLID_testset.label = OLID_testset.label.apply(getscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>15923</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>27014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>30530</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13876</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>60133</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label\n",
       "0  15923      1\n",
       "1  27014      0\n",
       "2  30530      0\n",
       "3  13876      0\n",
       "4  60133      1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLID_testset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>#ConstitutionDay is revered by Conservatives, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>#FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>#Watching #Boomer getting the news that she is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>#NoPasaran: Unity demo to oppose the far-right...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...\n",
       "1  #ConstitutionDay is revered by Conservatives, ...\n",
       "2  #FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...\n",
       "3  #Watching #Boomer getting the news that she is...\n",
       "4  #NoPasaran: Unity demo to oppose the far-right..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(r'D:\\dataset\\clear_data')\n",
    "OLID_test_text = pd.read_csv('testset-levela.csv',usecols=['tweet'])\n",
    "OLID_test_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        democrats support antifa, muslim brotherho...\n",
       "1     is revered by conservatives, hated by progres...\n",
       "2                                first, it reduces ...\n",
       "3      getting the news that she is still up for pa...\n",
       "4    : unity demo to oppose the far-right in  鈥?  鈥...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out some useless handles\n",
    "import re\n",
    "reg_map = {\n",
    "    re.compile(\"rt [@0-9a-z_]{0,10}:\"),\n",
    "    re.compile(\"[a-zA-z]+://[^\\s]*\"),\n",
    "    re.compile('http|htttps…'),\n",
    "    re.compile('[a-z]*[:.]+\\S+'),\n",
    "    re.compile(\"@[0-9a-z]+\"),\n",
    "     re.compile(\"#[0-9a-z]+\"),\n",
    "    re.compile(\"RT[\\s]+\"),\n",
    "    re.compile('https?:\\/\\/\\S+'),\n",
    "}\n",
    "def lower_and_remove_with_reg(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    for v in reg_map:\n",
    "        text = v.sub(\"\", text)\n",
    "    return text\n",
    "\n",
    "# Filter out some useless handles\n",
    "OLID_test_text['tweet']=OLID_test_text['tweet'].apply(lower_and_remove_with_reg)\n",
    "OLID_test_text['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replaces periods with Spaces\n",
    "OLID_test_text['tweet'] =  OLID_test_text['tweet'].str.replace('[^a-zA-Z]', ' ') \n",
    "\n",
    "#Delete the short term\n",
    "OLID_test_text['tweet'] =  OLID_test_text['tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    democrats support antifa muslim brotherhood is...\n",
       "1    revered conservatives hated progressives socia...\n",
       "2                                        first reduces\n",
       "3    getting news still parole always makes smile t...\n",
       "4                unity demo oppose right enough enough\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop=stopwords.words('english')\n",
    "OLID_test_text['tweet'] =  OLID_test_text['tweet'].apply(lambda sen:\" \".join(x for x in sen.split() if x not in stop))\n",
    "OLID_test_text['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    democrat support antifa muslim brotherhood isi...\n",
       "1    revered conservative hated progressive sociali...\n",
       "2                                        first reduces\n",
       "3    getting news still parole always make smile tr...\n",
       "4                unity demo oppose right enough enough\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Part of speech reduction\n",
    "from textblob import Word\n",
    "OLID_test_text['tweet'] =  OLID_test_text['tweet'].apply(lambda x:\" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "OLID_test_text['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [democrat, support, antifa, muslim, brotherhoo...\n",
       "1    [revered, conservative, hated, progressive, so...\n",
       "2                                     [first, reduces]\n",
       "3    [getting, news, still, parole, always, make, s...\n",
       "4         [unity, demo, oppose, right, enough, enough]\n",
       "Name: word, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Delete handle\n",
    "#Participle\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import pos_tag\n",
    "tknzr = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "OLID_test_text['word'] =  OLID_test_text['tweet'].apply(tknzr.tokenize)\n",
    "OLID_test_text['word'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part-of-speech tagging\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "def get_pos(text):\n",
    "    token = word_tokenize(text)\n",
    "    word = (pos_tag(token))\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(democrat, JJ), (support, NN), (antifa, NN), ...\n",
       "1    [(revered, VBN), (conservative, JJ), (hated, V...\n",
       "2                        [(first, RB), (reduces, NNS)]\n",
       "3    [(getting, VBG), (news, NN), (still, RB), (par...\n",
       "4    [(unity, NN), (demo, NN), (oppose, RB), (right...\n",
       "Name: text_tag, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLID_test_text['text_tag'] =  OLID_test_text['tweet'].apply(get_pos)\n",
    "OLID_test_text['text_tag'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>word</th>\n",
       "      <th>text_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>15923</td>\n",
       "      <td>1</td>\n",
       "      <td>democrat support antifa muslim brotherhood isi...</td>\n",
       "      <td>[democrat, support, antifa, muslim, brotherhoo...</td>\n",
       "      <td>[(democrat, JJ), (support, NN), (antifa, NN), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>27014</td>\n",
       "      <td>0</td>\n",
       "      <td>revered conservative hated progressive sociali...</td>\n",
       "      <td>[revered, conservative, hated, progressive, so...</td>\n",
       "      <td>[(revered, VBN), (conservative, JJ), (hated, V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>30530</td>\n",
       "      <td>0</td>\n",
       "      <td>first reduces</td>\n",
       "      <td>[first, reduces]</td>\n",
       "      <td>[(first, RB), (reduces, NNS)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13876</td>\n",
       "      <td>0</td>\n",
       "      <td>getting news still parole always make smile tr...</td>\n",
       "      <td>[getting, news, still, parole, always, make, s...</td>\n",
       "      <td>[(getting, VBG), (news, NN), (still, RB), (par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>60133</td>\n",
       "      <td>1</td>\n",
       "      <td>unity demo oppose right enough enough</td>\n",
       "      <td>[unity, demo, oppose, right, enough, enough]</td>\n",
       "      <td>[(unity, NN), (demo, NN), (oppose, RB), (right...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label                                              tweet  \\\n",
       "0  15923      1  democrat support antifa muslim brotherhood isi...   \n",
       "1  27014      0  revered conservative hated progressive sociali...   \n",
       "2  30530      0                                      first reduces   \n",
       "3  13876      0  getting news still parole always make smile tr...   \n",
       "4  60133      1              unity demo oppose right enough enough   \n",
       "\n",
       "                                                word  \\\n",
       "0  [democrat, support, antifa, muslim, brotherhoo...   \n",
       "1  [revered, conservative, hated, progressive, so...   \n",
       "2                                   [first, reduces]   \n",
       "3  [getting, news, still, parole, always, make, s...   \n",
       "4       [unity, demo, oppose, right, enough, enough]   \n",
       "\n",
       "                                            text_tag  \n",
       "0  [(democrat, JJ), (support, NN), (antifa, NN), ...  \n",
       "1  [(revered, VBN), (conservative, JJ), (hated, V...  \n",
       "2                      [(first, RB), (reduces, NNS)]  \n",
       "3  [(getting, VBG), (news, NN), (still, RB), (par...  \n",
       "4  [(unity, NN), (demo, NN), (oppose, RB), (right...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLID_testset = pd.concat([OLID_testset,OLID_test_text],axis = 1)\n",
    "OLID_testset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLID_testset = OLID_testset[['tweet','word','text_tag','label']]\n",
    "OLID_testset.to_csv('OLID_testset.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a machine learning model\n",
    "1. Use bag-of-words model and TF-IDF respectively for text feature representation. The max_features parameter refers to the maximum value of the selected feature number, which is determined according to the data situation and needs\n",
    "\n",
    "2. Randomly divide the data set and training set\n",
    "\n",
    "3. Import algorithm model\n",
    "\n",
    "4. Training algorithm model\n",
    "\n",
    "5. Predict the text sentiment in the test set\n",
    "\n",
    "6. Assess the effect of classification\n",
    "\n",
    "7. Save the trained algorithm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>word</th>\n",
       "      <th>text_tag</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>native american take</td>\n",
       "      <td>['native', 'american', 'take']</td>\n",
       "      <td>[('native', 'JJ'), ('american', 'JJ'), ('take'...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>home drunk maga trump</td>\n",
       "      <td>['home', 'drunk', 'maga', 'trump']</td>\n",
       "      <td>[('home', 'NN'), ('drunk', 'NN'), ('maga', 'NN...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>amazon investigating chinese employee selling ...</td>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>[('amazon', 'NN'), ('investigating', 'VBG'), (...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>someone vetaken piece shit volcano</td>\n",
       "      <td>['someone', 'vetaken', 'piece', 'shit', 'volca...</td>\n",
       "      <td>[('someone', 'NN'), ('vetaken', 'VBD'), ('piec...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>obama wanted liberal illegals move state</td>\n",
       "      <td>['obama', 'wanted', 'liberal', 'illegals', 'mo...</td>\n",
       "      <td>[('obama', 'RB'), ('wanted', 'VBD'), ('liberal...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0                               native american take   \n",
       "1                              home drunk maga trump   \n",
       "2  amazon investigating chinese employee selling ...   \n",
       "3                 someone vetaken piece shit volcano   \n",
       "4           obama wanted liberal illegals move state   \n",
       "\n",
       "                                                word  \\\n",
       "0                     ['native', 'american', 'take']   \n",
       "1                 ['home', 'drunk', 'maga', 'trump']   \n",
       "2  ['amazon', 'investigating', 'chinese', 'employ...   \n",
       "3  ['someone', 'vetaken', 'piece', 'shit', 'volca...   \n",
       "4  ['obama', 'wanted', 'liberal', 'illegals', 'mo...   \n",
       "\n",
       "                                            text_tag  label  \n",
       "0  [('native', 'JJ'), ('american', 'JJ'), ('take'...    1.0  \n",
       "1  [('home', 'NN'), ('drunk', 'NN'), ('maga', 'NN...    1.0  \n",
       "2  [('amazon', 'NN'), ('investigating', 'VBG'), (...    0.0  \n",
       "3  [('someone', 'NN'), ('vetaken', 'VBD'), ('piec...    1.0  \n",
       "4  [('obama', 'RB'), ('wanted', 'VBD'), ('liberal...    0.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(r'D:\\dataset\\clear_data')\n",
    "\n",
    "OLID_trainset = pd.read_csv('OLID_trainset.csv')\n",
    "OLID_trainset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Random Forest Classifier \n",
    "Rf = RandomForestClassifier()\n",
    "\n",
    "# SVM Classifier \n",
    "Svm = SGDClassifier()\n",
    "\n",
    "# Naive Bayes \n",
    "Nb = MultinomialNB()\n",
    "\n",
    "#Confirm training data set\n",
    "x_train=OLID_trainset['text_tag'] #Independent variable\n",
    "y_train=OLID_trainset['label']  #Dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidfvectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.7, max_features=1000,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token...\n",
       "                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "                               early_stopping=False, epsilon=0.1, eta0=0.0,\n",
       "                               fit_intercept=True, l1_ratio=0.15,\n",
       "                               learning_rate='optimal', loss='hinge',\n",
       "                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "                               penalty='l2', power_t=0.5, random_state=None,\n",
       "                               shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "                               verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Word bag model\n",
    "bow_vectorizer = CountVectorizer(max_df=0.6, min_df=1, max_features=1000)\n",
    "\n",
    "# TF-IDF feature\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.7, min_df=1, max_features=1000)\n",
    "\n",
    "#Use model\n",
    "Svm_pipe = make_pipeline(tfidf_vectorizer,Svm)\n",
    "Svm_pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('countvectorizer',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=0.6,\n",
       "                                 max_features=1000, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('multinomialnb',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Word bag model\n",
    "bow_vectorizer = CountVectorizer(max_df=0.6, min_df=1, max_features=1000)\n",
    "\n",
    "# TF-IDF feature\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.7, min_df=1, max_features=1000)\n",
    "\n",
    "#Use model\n",
    "Nb_pipe = make_pipeline(bow_vectorizer,Nb)\n",
    "Nb_pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randoom forest parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidfvectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.6, max_features=1000,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token...\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=None, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Word bag model\n",
    "bow_vectorizer = CountVectorizer(max_df=0.5, min_df=1, max_features=1000,ngram_range=(1, 2))\n",
    "\n",
    "# TF-IDF feature\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.6, min_df=1, max_features=1000)\n",
    "\n",
    "#Use model\n",
    "Rf_pipe = make_pipeline(tfidf_vectorizer,Rf)\n",
    "Rf_pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #使用词袋模型\n",
    "# pipe = make_pipeline(bow_vectorizer,Rf)\n",
    "# pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nb_param_grid = {randomforest__ : ['','']}\n",
    "# TF-IDF feature\n",
    "# pipe = make_pipeline(tfidf_vectorizer,Nb)\n",
    "# grid_search = GridSearchCV(pipe, Nb_param_grid, cv=5)\n",
    "# grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #查看带有交叉验证的网格搜索，模型选择的最佳参数，以及测试数据集上的评价指标准确率\n",
    "# print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n",
    "# print(\"Best parameters: {}\".format(grid.best_params_))\n",
    "# print(\"Test set score: {:.2f}\".format(grid.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import test data set for testing and optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>word</th>\n",
       "      <th>text_tag</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>democrat support antifa muslim brotherhood isi...</td>\n",
       "      <td>['democrat', 'support', 'antifa', 'muslim', 'b...</td>\n",
       "      <td>[('democrat', 'JJ'), ('support', 'NN'), ('anti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>revered conservative hated progressive sociali...</td>\n",
       "      <td>['revered', 'conservative', 'hated', 'progress...</td>\n",
       "      <td>[('revered', 'VBN'), ('conservative', 'JJ'), (...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>first reduces</td>\n",
       "      <td>['first', 'reduces']</td>\n",
       "      <td>[('first', 'RB'), ('reduces', 'NNS')]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>getting news still parole always make smile tr...</td>\n",
       "      <td>['getting', 'news', 'still', 'parole', 'always...</td>\n",
       "      <td>[('getting', 'VBG'), ('news', 'NN'), ('still',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>unity demo oppose right enough enough</td>\n",
       "      <td>['unity', 'demo', 'oppose', 'right', 'enough',...</td>\n",
       "      <td>[('unity', 'NN'), ('demo', 'NN'), ('oppose', '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  democrat support antifa muslim brotherhood isi...   \n",
       "1  revered conservative hated progressive sociali...   \n",
       "2                                      first reduces   \n",
       "3  getting news still parole always make smile tr...   \n",
       "4              unity demo oppose right enough enough   \n",
       "\n",
       "                                                word  \\\n",
       "0  ['democrat', 'support', 'antifa', 'muslim', 'b...   \n",
       "1  ['revered', 'conservative', 'hated', 'progress...   \n",
       "2                               ['first', 'reduces']   \n",
       "3  ['getting', 'news', 'still', 'parole', 'always...   \n",
       "4  ['unity', 'demo', 'oppose', 'right', 'enough',...   \n",
       "\n",
       "                                            text_tag  label  \n",
       "0  [('democrat', 'JJ'), ('support', 'NN'), ('anti...      1  \n",
       "1  [('revered', 'VBN'), ('conservative', 'JJ'), (...      0  \n",
       "2              [('first', 'RB'), ('reduces', 'NNS')]      0  \n",
       "3  [('getting', 'VBG'), ('news', 'NN'), ('still',...      0  \n",
       "4  [('unity', 'NN'), ('demo', 'NN'), ('oppose', '...      1  "
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(r'D:\\dataset\\clear_data')\n",
    "\n",
    "OLID_testset = pd.read_csv('OLID_testset.csv')\n",
    "OLID_testset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=OLID_testset['word']\n",
    "y_test=OLID_testset['label']\n",
    "\n",
    "#Make predictions\n",
    "y_pred = Rf_pipe.predict(x_test) \n",
    "#Save the prediction results to the dataframe\n",
    "df = pd.DataFrame(x_test) \n",
    "df['y_test']=y_test\n",
    "df['pred']=y_pred\n",
    "label = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87       620\n",
      "           1       0.72      0.45      0.55       240\n",
      "\n",
      "    accuracy                           0.80       860\n",
      "   macro avg       0.77      0.69      0.71       860\n",
      "weighted avg       0.79      0.80      0.78       860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, y_pred,labels=label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6898521505376344"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[579  41]\n",
      " [133 107]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "sns.set()\n",
    "f,ax=plt.subplots()\n",
    "C2= confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "print(C2) \n",
    "\n",
    "#Heat map\n",
    "sns.heatmap(C2,annot=True,ax=ax,cbar = None, cmap = 'Blues', fmt='g')\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "ax.set_title('confusion matrix')\n",
    "ax.set_xlabel('predict')\n",
    "ax.set_ylabel('true')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rf_pipe.pkl']"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "# Save to sklearn's own file format\n",
    "joblib.dump(Rf_pipe, 'Rf_pipe.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
